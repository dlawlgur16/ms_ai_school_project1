import time
import numpy as np
import gradio as gr
from io import BytesIO
from PIL import Image
from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient
from msrest.authentication import ApiKeyCredentials

# === Detection ëª¨ë¸ ì„¤ì • ===
DETECTION_PREDICTION_ENDPOINT = "YOUR_DETECTION_ENDPOINT"  # Azure Custom Vision Detection ì—”ë“œí¬ì¸íŠ¸ ì…ë ¥
DETECTION_PREDICTION_KEY = "YOUR_DETECTION_KEY"  # Azure Custom Vision Detection í‚¤ ì…ë ¥
DETECTION_PROJECT_ID = "YOUR_DETECTION_PROJECT_ID"  # Detection í”„ë¡œì íŠ¸ ID ì…ë ¥
DETECTION_ITERATION_NAME = "YOUR_DETECTION_ITERATION_NAME"  # Detection ëª¨ë¸ iteration ì´ë¦„ ì…ë ¥


detection_credentials = ApiKeyCredentials(in_headers={"Prediction-key": DETECTION_PREDICTION_KEY})
detection_predictor = CustomVisionPredictionClient(
    endpoint=DETECTION_PREDICTION_ENDPOINT,
    credentials=detection_credentials
)

# === Classification ëª¨ë¸ ì„¤ì • ===
classification_prediction_endpoint = "YOUR_CLASSIFICATION_ENDPOINT"  # Azure Custom Vision Classification ì—”ë“œí¬ì¸íŠ¸ ì…ë ¥
classification_prediction_key = "YOUR_CLASSIFICATION_KEY"  # Azure Custom Vision Classification í‚¤ ì…ë ¥
classification_project_id = "YOUR_CLASSIFICATION_PROJECT_ID"  # Classification í”„ë¡œì íŠ¸ ID ì…ë ¥
classification_publish_iteration_name = "YOUR_CLASSIFICATION_ITERATION_NAME"  # Classification ëª¨ë¸ iteration ì´ë¦„ ì…ë ¥

classification_credentials = ApiKeyCredentials(in_headers={"Prediction-key": classification_prediction_key})
classification_predictor = CustomVisionPredictionClient(
    endpoint=classification_prediction_endpoint, 
    credentials=classification_credentials
)

# === ì„¤ì • ê°’ ===
FRAME_INTERVAL = 0.2   # 0.2ì´ˆ ê°„ê²© (ì´ˆë‹¹ 5í”„ë ˆì„)
WINDOW_SIZE = 5        # ë¶„ì„ ìœˆë„ìš° í¬ê¸° (5í”„ë ˆì„ ê¸°ì¤€)
global_time_points = []   # ê° í”„ë ˆì„ì˜ ì‹œê°„(ì´ˆ)
global_kss_values = []    # ê° í”„ë ˆì„ì˜ KSS ì ìˆ˜
global_frame_count = 0
last_processed_time = 0

kss_mapping = {
    "ìš´ì „í•˜ë‹¤": 1,
    "ëˆˆë¹„ë¹„ê¸°": 21,
    "ì–´ê¹¨ë¥¼ë‘ë“œë¦¬ë‹¤": 25,
    "ëª©ì„ë§Œì§€ë‹¤": 25,
    "í•˜í’ˆ": 36,
    "ëº¨ì„ë•Œë¦¬ë‹¤": 64,
    "ê¾¸ë²…ê¾¸ë²…ì¡¸ë‹¤": 81,
    "ëª¸ëª»ê°€ëˆ„ê¸°": 100
}

risk_images = {
    "ë§¤ìš° ì•ˆì „": "image1.png",
    "ì•ˆì „": "image2.png",
    "ì£¼ì˜": "image3.png",
    "ìœ„í—˜": "image4.png",
    "ë§¤ìš° ìœ„í—˜": "image5.png"
}

def get_risk_status(avg_kss):
    if avg_kss < 9:
        return "ë§¤ìš° ì•ˆì „", "image1.png", None
    elif avg_kss < 20:
        return "ì•ˆì „", "image2.png", None
    elif avg_kss < 40:
        return "ì£¼ì˜", "image3.png", "ì•½ê°„ í”¼ë¡œí•´ë³´ì—¬ìš”.mp3"
    elif avg_kss < 75:
        return "ìœ„í—˜", "image4.png", "ë¯¸ì¹˜ì…¨ìŠµë‹ˆê¹Œ íœ´ë¨¼.mp3"
    else:
        return "ë§¤ìš° ìœ„í—˜", "image5.png", "ì‚¬ì´ë Œ.mp3"

def analyze_frame(image):
    try:
        global global_frame_count
        byte_io = BytesIO()
        image.save(byte_io, 'png')
        byte_io.seek(0)

        # 1ï¸âƒ£ Detection (ëª¸ì²´ ê²€ì¶œ í›„ í¬ë¡­)
        detection_results = detection_predictor.detect_image(DETECTION_PROJECT_ID, DETECTION_ITERATION_NAME, byte_io)
        cropped_image = image  # ê¸°ë³¸: ì›ë³¸ ì´ë¯¸ì§€

        for prediction in detection_results.predictions:
            if prediction.probability >= 0.9 and prediction.tag_name == "Body":
                img_width, img_height = image.size
                left = int(prediction.bounding_box.left * img_width)
                top = int(prediction.bounding_box.top * img_height)
                width = int(prediction.bounding_box.width * img_width)
                height = int(prediction.bounding_box.height * img_height)
                cropped_image = image.crop((left, top, left + width, top + height))
                break

        # 2ï¸âƒ£ Classification (ìš´ì „ì í–‰ë™ ì¸ì‹)
        byte_io = BytesIO()
        cropped_image.save(byte_io, 'png')
        byte_io.seek(0)

        classification_results = classification_predictor.classify_image(
            classification_project_id, classification_publish_iteration_name, byte_io
        )

        if not classification_results.predictions:
            return "ê²°ê³¼ ì—†ìŒ", "image1.png", None, 0

        top_prediction = max(classification_results.predictions, key=lambda x: x.probability)
        action_name = top_prediction.tag_name
        kss_score = kss_mapping.get(action_name, 0)

        # 3ï¸âƒ£ ì „ì—­ ë³€ìˆ˜ ì—…ë°ì´íŠ¸
        global_frame_count += 1
        current_frame_time = global_frame_count * FRAME_INTERVAL
        global_time_points.append(current_frame_time)
        global_kss_values.append(kss_score)

        # 4ï¸âƒ£ í‰ê·  KSS ê³„ì‚° (WINDOW_SIZE ê¸°ì¤€)
        if len(global_kss_values) < WINDOW_SIZE:
            return "ë¶€íŒ…ì¤‘...", "image1.png", None, 0

        avg_kss = np.mean(global_kss_values[-WINDOW_SIZE:])
        risk_state, risk_image, audio_file = get_risk_status(avg_kss)

        # 5ï¸âƒ£ ê²°ê³¼ ë°˜í™˜
        results_text = f"ğŸ¬ ì‹¤ì‹œê°„ í–‰ë™ ë¶„ì„\n{action_name}: {top_prediction.probability * 100:.2f}%\n"
        results_text += f"ğŸ”¹ KSS ì ìˆ˜: {kss_score} | í‰ê·  KSS: {avg_kss:.2f}\nğŸ“Š ìœ„í—˜ ìˆ˜ì¤€: {risk_state}\n"

        # ìë™ ì¬ìƒì„ ìœ„í•œ Audio ì»´í¬ë„ŒíŠ¸
        if audio_file:
            audio_output = gr.Audio(value=audio_file, autoplay=True)
        else:
            audio_output = None

        audio_output = gr.Audio(value=audio_file, autoplay=True) if audio_file else None
        return results_text, risk_image, audio_output, avg_kss

    except Exception as e:
        return f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}", "image1.png", None, 0

# === Gradio UI êµ¬ì„± ===
with gr.Blocks() as demo:
    with gr.Row():
        with gr.Column():
            input_img = gr.Image(sources=["webcam"], type="pil")
        with gr.Column():
            output_label = gr.Textbox(label="ğŸ” ë¶„ì„ ê²°ê³¼")
            output_image = gr.Image(label="ğŸ“Š ìœ„í—˜ ìˆ˜ì¤€", height=200, width=200)
            output_audio = gr.Audio(label="ğŸ”Š ìŒì„± ê²½ê³ ")
            output_slider = gr.Slider(minimum=0, maximum=100, step=1, label="âš ï¸ ìœ„í—˜ ìˆ˜ì¤€")

    input_img.stream(analyze_frame, [input_img], [output_label, output_image, output_audio, output_slider])

if __name__ == "__main__":
    demo.launch(debug=True)